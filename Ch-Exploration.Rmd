---
title: "MCA"
author: "Tuomas Tiihonen"
date: "10 joulukuuta 2017"
output: html_document
---

# Multiple Correspondence Analysis

Having now acquainted ourselves with the contents of the dataset, it's time to see whether there are any interesting structures hidden in the data. 

We will use the quantitative (integer) variables (indices 3,28,29) as supplementary variables in the MCA, while we base the actual categorisation on the categorical variables. As before, we will mostly use wider and taller figures, as the amount of information we wish to display is quite large.

## MCA Summaries

Our first task is to look at the summary of the MCA to see whether a low number of dimensions account for a high percentage of variance, which would indicate a significant finding in the analysis. In addition to the textual representation of the summary we will add a scree plot of the eigenvalues of the variables to determine a possible drop in the contribution levels to the variance.

```{r running and plotting MCA, eval = TRUE, fig.width = 12, fig.height = 12}

mca <- MCA(rawdata, ncp = 5, quanti.sup=c(3,28,29), graph = FALSE)
summary(mca)
fviz_eig(mca, ncp = 10)
```

The MCA summary shows that the contributions of the dimensions to the variance are not especially high, with the first dimension contributing just ~5.6% and the second dimension only ~4.4%. Therefore the explanatory potential of the model is not very substantial, but we will nevertheless use the analysis to gauge what little we can extract from the modest contribution of the first two dimensions to the variance.

From the scree plot of the eigenvalues we can clearly see that the contribution to variance evens out after the first two dimensions. Hence limiting further analysis to two dimensions is justifiable.

We will next look at the contributions of the variables, at value level, to the first two dimensions. By doing this we can already get a feeling of the groupings we may expect when we later look at the dimensions and the observations in a more graphical fashion.

## Contributions to dimensions

```{r, fig.width = 12, fig.height = 12}
vars <- get_mca_var(mca)
head(vars$cos2, 8)
```


```{r}
fviz_contrib(mca, choice = "var", axes = 1, top = 28)
```

In the contributions to the first dimension, we see the education variables dominating with failures.

```{r}
fviz_contrib(mca, choice = "var", axes = 2, top = 28)
```

In the contributions to the second dimension, the sexes contribute much of the variance.

## Variables in dimensions

```{r, fig.width = 12, fig.height = 12}
corrplot(vars$cos2, is.corr=FALSE)
fviz_mca_var(mca, choice = "mca.cor", 
            repel = TRUE, # Avoid text overlapping (slow)
            ggtheme = theme_minimal())
```

## Dimensions of the quantitative supplementary variables

```{r, fig.width = 12, fig.height = 12}
fviz_mca_var(mca, choice = "quanti.sup",
             ggtheme = theme_minimal())
```

As we can see, the absences grow along dimension 2, while the final grade and age are nearly opposites on dimension 1.

## MCA biplot

```{r, fig.width = 12, fig.height = 12}
fviz_mca_biplot(mca, repel = TRUE, ggtheme = theme_minimal())
```

## Variable categories in dimensions

```{r, fig.width = 12, fig.height = 12}
fviz_mca_var(mca, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE, # avoid text overlapping (slow)
             ggtheme = theme_minimal()
             )
fviz_mca_ind(mca, col.ind = "cos2", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, # Avoid text overlapping (slow if many points)
             ggtheme = theme_minimal())
```

While the dimensions' contributions to the total variance are not discernible, some of the values of the variables are relatively closely grouped together. For example, a high amount of free time seems to be closely matched with going out a lot, and both the mother's and father's employment as teachers seem to coincide. Similarly, a low amount of study time seems to be close to the high use of alcohol.

If we select values that are \ge\pm.5 on both dimensions, we end up with the following groupings in the four quadrants:

Top-left:

* Father's job is a teacher
* Mother's job is a teacher
* Mother's job is in healthcare
* Mother has at least a secondary education
* Student's final grade is in the highest quartile

Top-right

* Student doesn't strive for higher education
* Travel time is relatively high (4)
* Study time is very low (1)
* Student has failed courses
* Student consumes a high amount of alcohol

Bottom-right

* Mother has not completed secondary education
* Student has no home Internet connection
* Mother stays home
* Student has a very low amount of free time (1)

Bottom-left

* Father works in healthcare

While the dimensions explain a low portion of the variance, the groupings can be tentatively used for e.g. identifying students who would benefit from supportive measures in their education. We can also use other forms of analysis to measure whether some of the variables correlate to study results (as we have done in the next section).

## Concentration ellipses

One quite intuitive and graphical way to spot whether our variables actually have explanatory power within their dimensions is to plot the variables on the two-dimensional space with concentration ellipses.

```{r}
fviz_ellipses(mca, addEllipses=TRUE, "failures", geom = "point")
fviz_ellipses(mca, "Medu", geom = "point")
fviz_ellipses(mca, "Fedu", geom = "point")
fviz_ellipses(mca, "Mjob", geom = "point")
fviz_ellipses(mca, "Fjob", geom = "point")
fviz_ellipses(mca, "high_use", geom = "point")
```

It is obvious from the lack of individuals within the most of the ellipses that the variables are not very representative by themselves in the two-dimensional space.

To wrap things up, we will resort to a factor map of the values of variables.

```{r, fig.width = 12, fig.height = 12}
plot(mca, habillage = "quali", invisible=c("ind"))
```

## Summary of the MCA 

As is abundantly evident already, the Multiple Correspondence Analysis failed to explain more than 10% of the variance for the first two easily graphically representable dimensions, and as we could see from the MCA summary in the early stage of our analysis, the cumulative contributions to the variance did not cross the 50% mark until the 17th dimension. Hence the original and constructed factor variables cannot be categorised in a statistically significant manner. 

## Hypothesis

As we did not find any significant categories within the data, the null hypothesis is proved as valid.
